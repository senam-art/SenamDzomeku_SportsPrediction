{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "WgEZ4WARB-zP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRIwcaqZBm7a",
        "outputId": "57b94819-a801-4fdd-8261-4ad60833a886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your CSV file\n",
        "train_path = '/content/drive/My Drive/dataset/male_players (legacy).csv'\n",
        "test_path=  '/content/drive/My Drive/dataset/players_22.csv'\n",
        "\n"
      ],
      "metadata": {
        "id": "ZecMSDZeCxku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "train_data = pd.read_csv(train_path)\n",
        "test_data = pd.read_csv(test_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN-QVeWbDXYA",
        "outputId": "4ccb28df-0250-4bf3-e3cc-39eeb66d8a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-a06ee600c767>:2: DtypeWarning: Columns (108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_data = pd.read_csv(train_path)\n",
            "<ipython-input-20-a06ee600c767>:3: DtypeWarning: Columns (25,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  test_data = pd.read_csv(test_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n"
      ],
      "metadata": {
        "id": "7oQNdpRIKDpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "missing_percentages_train = train_data.isnull().mean() * 100\n",
        "\n",
        "missing_percentages_test = test_data.isnull().mean() * 100\n",
        "\n",
        "# Filter columns where missing percentage is 40% or more\n",
        "columns_with_high_missing1 = missing_percentages_train[missing_percentages_train >= 40].index.tolist()\n",
        "\n",
        "columns_with_high_missing2 = missing_percentages_test[missing_percentages_test >= 40].index.tolist()\n",
        "\n",
        "\n",
        "# Print or return the columns with 40% or more missing values\n",
        "print(\"Columns with 40% or more missing values:\")\n",
        "print(columns_with_high_missing1)\n",
        "\n",
        "\n",
        "# Print or return the columns with 40% or more missing values\n",
        "print(\"Columns with 40% or more missing values:\")\n",
        "print(columns_with_high_missing2)"
      ],
      "metadata": {
        "id": "OMg0e2XRYWP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a152a64-6a1d-4a30-91f0-ee047a536edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with 40% or more missing values:\n",
            "['club_loaned_from', 'nation_team_id', 'nation_position', 'nation_jersey_number', 'player_tags', 'player_traits', 'goalkeeping_speed']\n",
            "Columns with 40% or more missing values:\n",
            "['club_loaned_from', 'nation_team_id', 'nation_position', 'nation_jersey_number', 'player_tags', 'player_traits', 'goalkeeping_speed', 'nation_logo_url']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping columns"
      ],
      "metadata": {
        "id": "rhfkmkvuAWjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy = \"mean\")\n",
        "\n",
        "# Drop columns that are not useful for prediction\n",
        "columns_to_drop_train = ['player_id', 'player_url', 'fifa_version', 'fifa_update', 'fifa_update_date',\n",
        "                   'short_name', 'long_name','player_face_url', 'club_jersey_number','club_loaned_from','club_team_id',\n",
        "                   'club_joined_date','dob', 'nationality_id', 'nationality_name','nation_jersey_number',\n",
        "                   'nation_team_id','nation_jersey_number', 'player_tags', 'player_traits','real_face','nation_position']\n",
        "\n",
        "columns_to_drop_test = ['sofifa_id','player_url', 'short_name', 'long_name',\n",
        "                   'club_team_id', 'club_joined','dob',\n",
        "                   'nationality_id', 'nationality_name', 'nation_team_id',\n",
        "                   'player_tags', 'player_traits', 'player_face_url',\n",
        "                   'club_logo_url', 'club_flag_url', 'nation_logo_url', 'nation_flag_url','player_face_url','club_loaned_from','real_face','nation_position']\n",
        "\n",
        "\n",
        "train_data_cleaned = train_data.drop(columns=columns_to_drop_train)\n",
        "test_data_cleaned = test_data.drop(columns=columns_to_drop_test)\n",
        "\n",
        "#dropping postions in training data\n",
        "\n",
        "columns_to_drop_train2 = train_data_cleaned.columns[train_data_cleaned.columns.get_loc('ls'):train_data_cleaned.columns.get_loc('gk') + 1]\n",
        "train_data_cleaned = train_data_cleaned.drop(columns=columns_to_drop_train2)\n",
        "test_data_cleaned = test_data_cleaned.drop(columns=columns_to_drop_train2)\n",
        "\n",
        "# Separate numeric and categorical columns\n",
        "numeric_features_train = train_data_cleaned.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features_train = train_data_cleaned.select_dtypes(include=['object']).columns\n",
        "\n",
        "#grouping ages\n",
        "train_data_cleaned['age_group'] = pd.cut(train_data_cleaned['age'], bins=[0, 25, 30, 35, 40, 100], labels=['Under 25', '25-30', '30-35', '35-40', 'Over 40'])\n",
        "train_data_cleaned['age_group'] = train_data_cleaned['age_group'].astype(str)\n",
        "\n",
        "#grouping ages\n",
        "test_data_cleaned['age_group'] = pd.cut(train_data_cleaned['age'], bins=[0, 25, 30, 35, 40, 100], labels=['Under 25', '25-30', '30-35', '35-40', 'Over 40'])\n",
        "test_data_cleaned['age_group'] = train_data_cleaned['age_group'].astype(str)\n",
        "\n",
        "numeric_features_test = test_data_cleaned.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features_test = test_data_cleaned.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Impute missing values for numeric features\n",
        "numeric_imputer = SimpleImputer(strategy='mean')\n",
        "train_data_cleaned[numeric_features_train] = numeric_imputer.fit_transform(train_data_cleaned[numeric_features_train])\n",
        "test_data_cleaned[numeric_features_test] = numeric_imputer.fit_transform(test_data_cleaned[numeric_features_test])\n",
        "\n",
        "\n",
        "#dropping rows with missing values\n",
        "train_data_cleaned = train_data_cleaned.dropna()\n",
        "test_data_cleaned = test_data_cleaned.dropna()\n",
        "\n",
        "\n",
        "\n",
        "#print(train_data_cleaned.info())\n",
        "# print(test_data_cleaned.info())\n"
      ],
      "metadata": {
        "id": "ZqCP4EF_cSZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc12beb3-c81f-49a1-ea2f-cc87ef756bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 159810 entries, 0 to 161582\n",
            "Data columns (total 63 columns):\n",
            " #   Column                          Non-Null Count   Dtype  \n",
            "---  ------                          --------------   -----  \n",
            " 0   player_positions                159810 non-null  object \n",
            " 1   overall                         159810 non-null  float64\n",
            " 2   potential                       159810 non-null  float64\n",
            " 3   value_eur                       159810 non-null  float64\n",
            " 4   wage_eur                        159810 non-null  float64\n",
            " 5   age                             159810 non-null  float64\n",
            " 6   height_cm                       159810 non-null  float64\n",
            " 7   weight_kg                       159810 non-null  float64\n",
            " 8   league_id                       159810 non-null  float64\n",
            " 9   league_name                     159810 non-null  object \n",
            " 10  league_level                    159810 non-null  float64\n",
            " 11  club_name                       159810 non-null  object \n",
            " 12  club_position                   159810 non-null  object \n",
            " 13  club_contract_valid_until_year  159810 non-null  float64\n",
            " 14  preferred_foot                  159810 non-null  object \n",
            " 15  weak_foot                       159810 non-null  float64\n",
            " 16  skill_moves                     159810 non-null  float64\n",
            " 17  international_reputation        159810 non-null  float64\n",
            " 18  work_rate                       159810 non-null  object \n",
            " 19  body_type                       159810 non-null  object \n",
            " 20  release_clause_eur              159810 non-null  float64\n",
            " 21  pace                            159810 non-null  float64\n",
            " 22  shooting                        159810 non-null  float64\n",
            " 23  passing                         159810 non-null  float64\n",
            " 24  dribbling                       159810 non-null  float64\n",
            " 25  defending                       159810 non-null  float64\n",
            " 26  physic                          159810 non-null  float64\n",
            " 27  attacking_crossing              159810 non-null  float64\n",
            " 28  attacking_finishing             159810 non-null  float64\n",
            " 29  attacking_heading_accuracy      159810 non-null  float64\n",
            " 30  attacking_short_passing         159810 non-null  float64\n",
            " 31  attacking_volleys               159810 non-null  float64\n",
            " 32  skill_dribbling                 159810 non-null  float64\n",
            " 33  skill_curve                     159810 non-null  float64\n",
            " 34  skill_fk_accuracy               159810 non-null  float64\n",
            " 35  skill_long_passing              159810 non-null  float64\n",
            " 36  skill_ball_control              159810 non-null  float64\n",
            " 37  movement_acceleration           159810 non-null  float64\n",
            " 38  movement_sprint_speed           159810 non-null  float64\n",
            " 39  movement_agility                159810 non-null  float64\n",
            " 40  movement_reactions              159810 non-null  float64\n",
            " 41  movement_balance                159810 non-null  float64\n",
            " 42  power_shot_power                159810 non-null  float64\n",
            " 43  power_jumping                   159810 non-null  float64\n",
            " 44  power_stamina                   159810 non-null  float64\n",
            " 45  power_strength                  159810 non-null  float64\n",
            " 46  power_long_shots                159810 non-null  float64\n",
            " 47  mentality_aggression            159810 non-null  float64\n",
            " 48  mentality_interceptions         159810 non-null  float64\n",
            " 49  mentality_positioning           159810 non-null  float64\n",
            " 50  mentality_vision                159810 non-null  float64\n",
            " 51  mentality_penalties             159810 non-null  float64\n",
            " 52  mentality_composure             159810 non-null  float64\n",
            " 53  defending_marking_awareness     159810 non-null  float64\n",
            " 54  defending_standing_tackle       159810 non-null  float64\n",
            " 55  defending_sliding_tackle        159810 non-null  float64\n",
            " 56  goalkeeping_diving              159810 non-null  float64\n",
            " 57  goalkeeping_handling            159810 non-null  float64\n",
            " 58  goalkeeping_kicking             159810 non-null  float64\n",
            " 59  goalkeeping_positioning         159810 non-null  float64\n",
            " 60  goalkeeping_reflexes            159810 non-null  float64\n",
            " 61  goalkeeping_speed               159810 non-null  float64\n",
            " 62  age_group                       159810 non-null  object \n",
            "dtypes: float64(55), object(8)\n",
            "memory usage: 78.0+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Encoding non numeric data"
      ],
      "metadata": {
        "id": "k659GKf1GHaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "#function to encode data\n",
        "def ordinal_encode(data):\n",
        "\n",
        "    # Get the list of column names with dtype 'object' (categorical features)\n",
        "    categorical_features_train = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    # Initialize ordinal encoder\n",
        "    ordinal_encoder = OrdinalEncoder()\n",
        "\n",
        "    # Fit and transform the categorical features in the training data\n",
        "    train_data_cat_encoded = ordinal_encoder.fit_transform(train_data_cleaned[categorical_features_train])\n",
        "\n",
        "\n",
        "    # Replace original categorical columns with encoded values\n",
        "    train_data_cleaned[categorical_features_train] = train_data_cat_encoded\n",
        "\n",
        "\n",
        "    return train_data_cleaned\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_data_cleaned_encoded = ordinal_encode(train_data_cleaned)\n",
        "test_data_cleaned_encoded = ordinal_encode(test_data_cleaned)\n",
        "\n",
        "# train_data_cleaned_encoded.info()\n",
        "\n",
        "# test_data_cleaned_encoded.info()\n",
        "\n",
        "# test_data_cleaned_encoded.head(5)"
      ],
      "metadata": {
        "id": "EhnuVjcoMeMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature engineering\n",
        "\n",
        "def feature_engineering(data):\n",
        "    # Calculate BMI\n",
        "    data['bmi'] = data['weight_kg'] / ((data['height_cm'] / 100) ** 2)\n",
        "\n",
        "    # Calculate overall skill rating\n",
        "    skill_columns = ['skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control']\n",
        "    data['overall_skill_rating'] = data[skill_columns].mean(axis=1)\n",
        "\n",
        "    # Calculate overall attacking rating\n",
        "    attacking_columns = ['attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy', 'attacking_short_passing', 'attacking_volleys']\n",
        "    data['overall_attacking_rating'] = data[attacking_columns].mean(axis=1)\n",
        "\n",
        "    # Calculate overall movement rating\n",
        "    movement_columns = ['movement_acceleration', 'movement_sprint_speed', 'movement_agility', 'movement_reactions', 'movement_balance']\n",
        "    data['overall_movement_rating'] = data[movement_columns].mean(axis=1)\n",
        "\n",
        "    # Calculate overall defending rating\n",
        "    defending_columns = ['defending_marking_awareness', 'defending_standing_tackle', 'defending_sliding_tackle']\n",
        "    data['overall_defending_rating'] = data[defending_columns].mean(axis=1)\n",
        "\n",
        "    # Calculate overall goalkeeping rating\n",
        "    goalkeeping_columns = ['goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning', 'goalkeeping_reflexes']\n",
        "    data['overall_goalkeeping_rating'] = data[goalkeeping_columns].mean(axis=1)\n",
        "\n",
        "    # Calculate overall mentality rating\n",
        "    mentality_columns = ['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision']\n",
        "    data['overall_mentality_rating'] = data[mentality_columns].mean(axis=1)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply feature engineering function to datasets\n",
        "train_data_cleaned = feature_engineering(train_data_cleaned)\n",
        "\n",
        "test_data_cleaned = feature_engineering(test_data_cleaned)\n",
        "\n",
        "# train_data_cleaned.info())\n",
        "\n",
        "# test_data_cleaned.info()\n",
        "#train_data_cleaned.head()"
      ],
      "metadata": {
        "id": "ga8e6b2cYkJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using feature importance to select best features (correlation matrix)"
      ],
      "metadata": {
        "id": "Dwnm2zCPS_lQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "target_variable = 'overall'\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr_matrix = train_data_cleaned.corr()\n",
        "\n",
        "correlation_with_overall = corr_matrix['overall'].sort_values(ascending=False)\n",
        "\n",
        "# # Print the top correlations\n",
        "# print(\"Top Correlations with Overall Rating:\")\n",
        "# print(correlation_with_overall.head(30))\n",
        "\n",
        "\n",
        "\n",
        "# Set correlation threshold\n",
        "correlation_threshold = 0.5\n",
        "\n",
        "\n",
        "#Select features with correlation higher than the positive threshold\n",
        "positive_features = corr_matrix[corr_matrix['overall'] >= correlation_threshold].index.tolist()\n",
        "\n",
        "#Select features with correlation lower than the negative threshold\n",
        "negative_features = corr_matrix[corr_matrix['overall'] <= -correlation_threshold].index.tolist()\n",
        "\n",
        "#Combine positive and negative features (excluding 'overall' itself)\n",
        "relevant_features = list(set(positive_features + negative_features))\n",
        "\n",
        "# Print the relevant features\n",
        "print(\"Relevant Features based on Correlation:\")\n",
        "print(relevant_features)\n",
        "\n",
        "train_data_final= train_data_cleaned[relevant_features]\n",
        "\n",
        "test_data_final = test_data_cleaned[relevant_features]\n",
        "train_data_final.columns\n"
      ],
      "metadata": {
        "id": "oLUOm3vqxfoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b16a45-888e-4feb-e615-957f58dc0c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relevant Features based on Correlation:\n",
            "['dribbling', 'overall', 'potential', 'mentality_composure', 'passing', 'wage_eur', 'overall_mentality_rating', 'attacking_short_passing', 'value_eur', 'movement_reactions']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['dribbling', 'overall', 'potential', 'mentality_composure', 'passing',\n",
              "       'wage_eur', 'overall_mentality_rating', 'attacking_short_passing',\n",
              "       'value_eur', 'movement_reactions'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model selection and Tuning"
      ],
      "metadata": {
        "id": "lCFJs6jbeZVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ],
      "metadata": {
        "id": "TDsfzlsXTUA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "# Splitting data into features (X) and target variable (y)\n",
        "X = train_data_final.drop(columns=['overall'])  # Features\n",
        "y = train_data_final['overall']  # Target variable\n",
        "\n",
        "# Splitting data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oiPsEHBOUAv5"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Linear Regression"
      ],
      "metadata": {
        "id": "bWQdvZVGprVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#linear regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the model\n",
        "lr_model = LinearRegression()\n",
        "\n",
        "# Fit the model on the training data\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred_lr = lr_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE on the validation set\n",
        "lr_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_lr))\n",
        "print(f\"Linear Regression Validation RMSE: {lr_val_rmse}\")\n"
      ],
      "metadata": {
        "id": "lclpdcKBkH2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2551ce16-52ca-45e8-de65-0b46ba84d5d0"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Validation RMSE: 2.8967782557457977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decision Trees"
      ],
      "metadata": {
        "id": "85XzaeKWpvTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the model\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred_dt = dt_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE on the validation set\n",
        "dt_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_dt))\n",
        "print(f\"Decision Tree Regressor Validation RMSE: {dt_val_rmse}\")\n"
      ],
      "metadata": {
        "id": "MbyKy9s5oZqA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be9adf2-d596-44b8-f85c-ef4caf772b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor Validation RMSE: 1.9584791959333072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest"
      ],
      "metadata": {
        "id": "5Z1ALR7op0ZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest regressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Cross-validation training and evaluation\n",
        "rf_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "rf_rmse_scores = np.sqrt(-rf_scores)\n",
        "\n",
        "# Fit the model on the entire training data\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on validation set\n",
        "y_val_pred_rf = rf_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE on validation set\n",
        "rf_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_rf))\n",
        "print(f\"RandomForestRegressor Validation RMSE: {rf_val_rmse}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "ZksQnADse9XU",
        "outputId": "8f12752f-9ce8-418b-b98f-7d03712c8e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e3b7fa573280>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Fit the model on the entire training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Predictions on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XG Boost"
      ],
      "metadata": {
        "id": "1ip02OVSp5II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "# Initialize XGBoostRegressor\n",
        "xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "# Cross-validation training and evaluation\n",
        "xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
        "xgb_rmse_scores = np.sqrt(-xgb_scores)\n",
        "\n",
        "# Fit the model on the entire training data\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on validation set\n",
        "y_val_pred_xgb = xgb_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE on validation set\n",
        "xgb_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_xgb))\n",
        "print(f\"XGBoostRegressor Validation RMSE: {xgb_val_rmse}\")"
      ],
      "metadata": {
        "id": "dP6X0pdSigwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypertuning Random Forest and XG Boost"
      ],
      "metadata": {
        "id": "yqS0oozpnIsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random forest"
      ],
      "metadata": {
        "id": "pgva3hxNnV1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "import pickle\n",
        "import joblib\n",
        "\n",
        "# Define the parameter grid\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize RandomForestRegressor\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_distributions,\n",
        "                                   n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
        "# Fit the RandomizedSearchCV\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(f\"Best parameters found: {best_params}\")\n",
        "\n",
        "# Train the model with tuned parameters\n",
        "best_rf_model = random_search.best_estimator_\n",
        "\n",
        "# Cross-validation training and evaluation with the best parameters\n",
        "rf_scores = cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "rf_rmse_scores = np.sqrt(-rf_scores)\n",
        "print(f\"Cross-validation RMSE scores: {rf_rmse_scores}\")\n",
        "print(f\"Average cross-validation RMSE: {np.mean(rf_rmse_scores)}\")\n",
        "\n",
        "# Fit the model on the entire training data with the best parameters\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on validation set\n",
        "y_val_pred_rf = best_rf_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE on validation set\n",
        "rf_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_rf))\n",
        "print(f\"RandomForestRegressor Validation RMSE with best parameters: {rf_val_rmse}\")\n",
        "\n",
        "# Save the tuned model to a file\n",
        "filename = '/content/drive/My Drive/dataset/rf_model.pkl'\n",
        "joblib.dump(best_rf_model, filename)\n",
        "print(f\"Saved best model to {filename}\")\n"
      ],
      "metadata": {
        "id": "ZyYFtkgsihRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd45c07-fdd4-41c1-fa7b-0295888ac27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns"
      ],
      "metadata": {
        "id": "sXSPTzBcVrww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f25d5ead-820b-49a7-bbfd-aef3d2938cc1"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['dribbling', 'potential', 'mentality_composure', 'passing', 'wage_eur',\n",
              "       'overall_mentality_rating', 'attacking_short_passing', 'value_eur',\n",
              "       'movement_reactions'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qygJReiIVrl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XG Boost"
      ],
      "metadata": {
        "id": "H5YjHdCPnZIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "    'gamma': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Initialize the XGBoost regressor\n",
        "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb_regressor, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit GridSearchCV to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# View the best parameters and the best score\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best RMSE: {np.sqrt(-grid_search.best_score_)}\")\n",
        "\n",
        "# Train the final model using the best parameters\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Fit the model on the entire training data\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred_xgb = best_xgb_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE on the validation set\n",
        "xgb_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_xgb))\n",
        "print(f\"XGBoost Regressor Validation RMSE: {xgb_val_rmse}\")\n",
        "\n",
        "# Save the tuned model to a file\n",
        "filename = '/content/drive/My Drive/dataset/xgb_model.pkl'\n",
        "pickle.dump(best_xgb_model, open(filename, 'wb'))\n",
        "print(f\"Saved best model to {filename}\")\n"
      ],
      "metadata": {
        "id": "cZtKz5StncGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Linear Hypertuning"
      ],
      "metadata": {
        "id": "aQEhWvUApGzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for alpha\n",
        "param_grid = {'alpha': [0.1, 1, 10, 100]}\n",
        "\n",
        "# Initialize the Ridge model\n",
        "ridge = Ridge()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "ridge_grid_search = GridSearchCV(estimator=ridge, param_grid=param_grid,\n",
        "                                 scoring='neg_mean_squared_error', cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit GridSearchCV to the data\n",
        "ridge_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# View the best parameters and the best score\n",
        "print(f\"Best parameters for Ridge: {ridge_grid_search.best_params_}\")\n",
        "print(f\"Best RMSE for Ridge: {np.sqrt(-ridge_grid_search.best_score_)}\")\n",
        "\n",
        "# Train the final Ridge model using the best parameters\n",
        "best_ridge_model = ridge_grid_search.best_estimator_\n",
        "\n",
        "# Fit the model on the entire training data\n",
        "best_ridge_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred_ridge = best_ridge_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE on the validation set\n",
        "ridge_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_ridge))\n",
        "print(f\"Ridge Regression Validation RMSE: {ridge_val_rmse}\")\n",
        "\n",
        "# Save the tuned model to a file\n",
        "filename = '/content/drive/My Drive/dataset/linear_model.pkl'\n",
        "pickle.dump(best_ridge_model, open(filename, 'wb'))\n",
        "print(f\"Saved best model to {filename}\")\n"
      ],
      "metadata": {
        "id": "lpWZWl98owmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22995921-ab41-4c30-fcbd-20f4b5649c06"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Best parameters for Ridge: {'alpha': 0.1}\n",
            "Best RMSE for Ridge: 2.903181617646342\n",
            "Ridge Regression Validation RMSE: 2.896778255606053\n",
            "Saved best model to /content/drive/My Drive/dataset/linear_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Optimization"
      ],
      "metadata": {
        "id": "NlZ5wgAGqL3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "dt_grid_search = GridSearchCV(estimator=dt, param_grid=param_grid,\n",
        "                              scoring='neg_mean_squared_error', cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Fit GridSearchCV to the data\n",
        "dt_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# View the best parameters and the best score\n",
        "print(f\"Best parameters for Decision Tree: {dt_grid_search.best_params_}\")\n",
        "print(f\"Best RMSE for Decision Tree: {np.sqrt(-dt_grid_search.best_score_)}\")\n",
        "\n",
        "# Train the final model using the best parameters\n",
        "best_dt_model = dt_grid_search.best_estimator_\n",
        "\n",
        "# Fit the model on the entire training data\n",
        "best_dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred_best_dt = best_dt_model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE on the validation set\n",
        "best_dt_val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred_best_dt))\n",
        "print(f\"Better Decision Tree Validation RMSE: {best_dt_val_rmse}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jdz9M8u3qLiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63495257-a7d8-4563-e198-ebbfba2ce7e1"
      },
      "execution_count": 73,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Decision Tree: {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
            "Best RMSE for Decision Tree: 1.75421677307553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py:277: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better Decision Tree Validation RMSE: 1.7124487617497988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the tuned model to a file\n",
        "filename = '/content/drive/My Drive/dataset/dt_model.pkl'\n",
        "pickle.dump(best_dt_model, open(filename, 'wb'))\n",
        "print(f\"Saved best model to {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKWT9TOAn_SD",
        "outputId": "a5d14132-b27f-4228-ad99-a969ce585b80"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best model to /content/drive/My Drive/dataset/dt_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save as a pickle file"
      ],
      "metadata": {
        "id": "iU7bUjqUgUDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Save the model to a file\n",
        "filename = 'rf_model.pkl'\n",
        "pickle.dump(rf_model, open(filename, 'wb'))\n",
        "print(f\"Saved model to {filename}\")"
      ],
      "metadata": {
        "id": "wovJtU1BgH5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n"
      ],
      "metadata": {
        "id": "WfqUZ6kwpQCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGB Boost Test"
      ],
      "metadata": {
        "id": "9LrNCSP7iiy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pickle\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = pickle.load(open('/content/drive/My Drive/dataset/xgb_model.pkl', 'rb'))\n",
        "\n",
        "\n",
        "# Select relevant features for prediction using .loc\n",
        "X_predict = test_data_final.loc[:, relevant_features]\n",
        "\n",
        "\n",
        "desired_order = ['potential', 'passing', 'overall_mentality_rating', 'attacking_short_passing', 'wage_eur', 'value_eur', 'mentality_composure', 'movement_reactions', 'dribbling']\n",
        "\n",
        "\n",
        "\n",
        "X_predict = test_data_final.drop(columns=['overall'])  # Features\n",
        "y_predict = test_data_final['overall']  # Target variable\n",
        "\n",
        "\n",
        "# Rearrange columns in test_data_final according to desired_order\n",
        "X_predict = X_predict.loc[:, desired_order]\n",
        "\n",
        "# Predict on the new dataset\n",
        "y_pred = loaded_model.predict(X_predict)\n",
        "\n",
        "\n",
        "# Calculate RMSE (Root Mean Squared Error)\n",
        "test_rmse = np.sqrt(mean_squared_error(y_predict, y_pred))\n",
        "print(f\"Test RMSE: {test_rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NVU26eCcZG0",
        "outputId": "236f6459-3809-42de-94ab-90a5ba5b5c45"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 1.3558535985061781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_predict.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1YJAJ7rqjdG",
        "outputId": "4cf509a4-aad3-4858-96c1-800184cd275b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['potential', 'passing', 'overall_mentality_rating',\n",
              "       'attacking_short_passing', 'wage_eur', 'value_eur',\n",
              "       'mentality_composure', 'movement_reactions', 'dribbling'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "KjXQRnGXjBF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the trained linear regression model\n",
        "linear_regression_model = joblib.load('/content/drive/My Drive/dataset/linear_model.pkl')\n",
        "\n",
        "\n",
        "y_test = test_data_final['overall']\n",
        "\n",
        "test_data_final_reordered = test_data_final.drop(columns=['overall'], errors='ignore')\n",
        "\n",
        "# Predict ratings for test data\n",
        "y_pred = linear_regression_model.predict(test_data_final_reordered)\n",
        "\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"Linear Regression Test RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "id": "okKUtR0li8HZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8887f0be-06e5-4ee8-81ee-20ed0747b1b1"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Test RMSE: 2.7323602043769153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "decision_tree_model = joblib.load('/content/drive/My Drive/dataset/dt_model.pkl')\n",
        "\n",
        "\n",
        "y_test = test_data_final['overall']\n",
        "\n",
        "# Drop the 'overall' column from the test data\n",
        "test_data_final_reordered = test_data_final.drop(columns=['overall'])\n",
        "\n",
        "\n",
        "# Predict ratings for test data\n",
        "y_pred = decision_tree_model.predict(test_data_final_reordered)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f\"Decision Tree Test RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txd1kK4Xq_DZ",
        "outputId": "44fbc4cb-1334-4c71-b34a-0a11b9ccb99a"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Test RMSE: 1.230949311099096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Decision Tree was the best model however, XGB Boost was the best ensemble moder, linear regression performed poorly compared to the others"
      ],
      "metadata": {
        "id": "qveUl2RG4sRh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJFnhmWH5M9_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}